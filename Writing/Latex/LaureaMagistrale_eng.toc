\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Motivation and background}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Theoretical framework and focus of the study}{2}{section.1.2}%
\contentsline {section}{\numberline {1.3}Research questions and objectives}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Methodology}{3}{section.1.4}%
\contentsline {section}{\numberline {1.5}Structure of the thesis}{3}{section.1.5}%
\contentsline {chapter}{\numberline {2}Machine learning: Some theoretical concepts}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Data collection and preprocessing}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}ETL}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Apache spark}{5}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Dealing with missing data}{6}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Dealing with imbalance data}{6}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}One-hot encoding}{7}{subsection.2.1.5}%
\contentsline {subsection}{\numberline {2.1.6}Ordinal encoding}{7}{subsection.2.1.6}%
\contentsline {subsection}{\numberline {2.1.7}Categorical embeddings}{7}{subsection.2.1.7}%
\contentsline {subsection}{\numberline {2.1.8}Feature selection}{8}{subsection.2.1.8}%
\contentsline {section}{\numberline {2.2}Machine learning models}{8}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Logistic regression}{8}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Decision tree classifier}{9}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Random forest classifier}{10}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Boosting: Gradient-boosted tree, XGBoost}{11}{subsection.2.2.4}%
\contentsline {section}{\numberline {2.3}Evaluation metrics}{12}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Confusion matrix}{12}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Precision, Recall, F-Measure}{12}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Area under the curve (ROC AUC, PR AUC)}{13}{subsection.2.3.3}%
\contentsline {chapter}{\numberline {3}Related work}{15}{chapter.3}%
\contentsline {section}{\numberline {3.1}Review: Techniques and Data}{15}{section.3.1}%
\contentsline {section}{\numberline {3.2}Summary}{16}{section.3.2}%
\contentsline {chapter}{\numberline {4}Energy provider case study: churn prediction machine learning model}{17}{chapter.4}%
\contentsline {section}{\numberline {4.1}Tools and libraries}{17}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Python}{17}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Apache Spark}{17}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Data collection}{18}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Data collection: ETL}{18}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Feature creation}{18}{subsection.4.2.2}%
\contentsline {section}{\numberline {4.3}Data description and understanding}{19}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}The churner profile}{19}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Data preprocessing and feature selection}{20}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Handling missing data}{20}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Dealing with categorical features}{22}{subsection.4.4.2}%
\contentsline {subsubsection}{One-hot encoding}{23}{section*.17}%
\contentsline {subsubsection}{Boolean encoding}{23}{section*.18}%
\contentsline {subsubsection}{Ordinal encoding}{23}{section*.19}%
\contentsline {subsubsection}{Categorical embeddings}{23}{section*.20}%
\contentsline {subsection}{\numberline {4.4.3}Train-Test split}{23}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}Imbalanced data}{24}{subsection.4.4.4}%
\contentsline {subsubsection}{Undersampling}{24}{section*.23}%
\contentsline {subsubsection}{Oversampling}{25}{section*.25}%
\contentsline {subsection}{\numberline {4.4.5}Feature selection}{26}{subsection.4.4.5}%
\contentsline {subsubsection}{Unique selector}{26}{section*.27}%
\contentsline {subsubsection}{Missing selector}{26}{section*.28}%
\contentsline {subsubsection}{Importance selector}{26}{section*.29}%
\contentsline {subsubsection}{Correlation selector}{26}{section*.31}%
\contentsline {subsubsection}{Recursive feature elimination}{26}{section*.33}%
\contentsline {subsection}{\numberline {4.4.6}The complete workflow}{27}{subsection.4.4.6}%
\contentsline {chapter}{\numberline {5}Models and results}{31}{chapter.5}%
\contentsline {section}{\numberline {5.1}Logistic regression}{31}{section.5.1}%
\contentsline {section}{\numberline {5.2}Decision tree classifier}{32}{section.5.2}%
\contentsline {section}{\numberline {5.3}Random forest classifier}{33}{section.5.3}%
\contentsline {section}{\numberline {5.4}Gradient-boosted tree classifier}{35}{section.5.4}%
\contentsline {section}{\numberline {5.5}XGBoost}{36}{section.5.5}%
\contentsline {section}{\numberline {5.6}Summary and analysis of the results}{38}{section.5.6}%
\contentsline {subsection}{\numberline {5.6.1}Random search}{40}{subsection.5.6.1}%
\contentsline {subsection}{\numberline {5.6.2}Threshold optimization and final results}{41}{subsection.5.6.2}%
\contentsline {subsection}{\numberline {5.6.3}Trying the best model on a different target}{42}{subsection.5.6.3}%
\contentsline {chapter}{\numberline {6}Conclusions}{45}{chapter.6}%
\contentsline {section}{\numberline {6.1}Conclusion}{45}{section.6.1}%
\contentsline {section}{\numberline {6.2}Suggestion for future research}{46}{section.6.2}%
\contentsline {chapter}{Bibliography}{47}{section*.70}%
